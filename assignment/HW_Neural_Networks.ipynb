{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW - Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1AaPcgEnXt5"
      },
      "source": [
        "!pip install matminer\n",
        "!pip install skorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtXFWcIstewu"
      },
      "source": [
        "from matminer.datasets.convenience_loaders import load_mp\n",
        "from matminer.featurizers.conversions import StrToComposition\n",
        "from matminer.featurizers.composition import ElementProperty\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiHkdAxytpn4"
      },
      "source": [
        "# Homework: Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3qTLs32yxC5"
      },
      "source": [
        "## Material Property Prediction: Bulk Modulus\n",
        "\n",
        "Reference: Dunn, A., Wang, Q., Ganose, A. et al. <a href='https://www.nature.com/articles/s41524-020-00406-3'>Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm</a>. npj Comput Mater 6, 138 (2020).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf50R4xPthhy"
      },
      "source": [
        "df = load_mp()  # loads dataset in a pandas DataFrame object\n",
        "\n",
        "# Convert formula to composition\n",
        "df = StrToComposition().featurize_dataframe(df, \"formula\", ignore_errors=True) \n",
        "\n",
        "# Create features based on composition\n",
        "ep_feat = ElementProperty.from_preset(preset_name=\"magpie\") \n",
        "\n",
        "# input the \"composition\" column to the featurizer\n",
        "df = ep_feat.featurize_dataframe(df, col_id=\"composition\", ignore_errors=True)  \n",
        "\n",
        "# drop rows with NaN values\n",
        "df = df.dropna(axis=0) \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW-HD_yf2aPM"
      },
      "source": [
        "# Create combined bulk & shear modulus task array\n",
        "y = df[['shear modulus', 'bulk modulus']].values\n",
        "\n",
        "# Drop non-numerical features and tasks from data frame\n",
        "excluded = ['shear modulus', 'bulk modulus', 'formula', 'composition', 'mpid', \\\n",
        "            'e_hull', 'gap pbe', 'elastic anisotropy', 'e_form']\n",
        "X = df.drop(excluded, axis=1).values\n",
        "\n",
        "# Standardize input data\n",
        "X = (X-X.mean(axis=-1, keepdims=True))/X.std(axis=-1, keepdims=True)\n",
        "\n",
        "# Convert numpy array to pytorch\n",
        "X = torch.tensor(X).float()\n",
        "y = torch.tensor(y).float()\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "634Kcg1pvx8Y"
      },
      "source": [
        "## Question 1: Visualize the data\n",
        "Visualize and comment on the data distribution for the tasks `bulk modulus` (k) and `shear modulus` (G). Perform a log-transformation of the data and re-plot the distributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2jKWojG3sQy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwX65uWSvx0B"
      },
      "source": [
        "## Question 2: Neural network hyperparameter optimization\n",
        "\n",
        "Split the dataset into 90% training and 10% testing. Build a neural network with 2 hidden layers and `nn.ReLU()` activation functions. Use `skorch` to optimize the parameters of the neural network using the log-transformed data. To the best of your ability, tune the dimension of the hidden layers and the learning rate to optimize the validation score. Feel free to also make the model deeper or add regularization such as batch normalization or dropout.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI5xongN3rJ-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbis3mqDvxkz"
      },
      "source": [
        "## Question 3: Evaluate performance\n",
        "\n",
        "Determine the test set performance (R2 score and mean absolute error) of your best performing model for the shear modulus (logG) and bulk modulus (logK) prediction. Compare with the results presented in the reference (see Figure 4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFHCV2Sp1wch"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}