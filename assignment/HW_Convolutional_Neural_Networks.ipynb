{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW - Convolutional Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhPMDESLt-R1"
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcCNoRg2uJf-"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import skorch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWuESQw7uRxY"
      },
      "source": [
        "## Homework: EuroSAT: A land use and land cover classification dataset\n",
        "\n",
        "<a href='https://arxiv.org/abs/1709.00029'>Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.</a> Patrick Helber, Benjamin Bischke, Andreas Dengel, Damian Borth. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/phelber/EuroSAT/master/eurosat_overview_small.jpg'>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hagSyd_I4flL"
      },
      "source": [
        "## Question 1: Use a pre-trained model\n",
        "\n",
        "In class we achieved a classification accuracy of 90.6% on the test dataset of EuroSAT. Can you improve the performance of this model?\n",
        "\n",
        "Ideas:\n",
        "- Try to adjust the learning rate or number of epochs\n",
        "- Try adding additional transforms to the preprocessing pipeline (see <a href='https://pytorch.org/docs/stable/torchvision/transforms.html'>torchvision.transforms</a>)\n",
        "- Try using a different pre-trained model (see <a href='https://pytorch.org/docs/stable/torchvision/models.html#classification'>torchvision.models</a>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmdbBTlUxdfu"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOuCXHlDuOqh"
      },
      "source": [
        "# http://madm.dfki.de/files/sentinel/EuroSAT.zip\n",
        "os.system(\"wget http://madm.dfki.de/files/sentinel/EuroSAT.zip\")\n",
        "os.system(\"unzip EuroSAT.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFW2NuWMxgBL"
      },
      "source": [
        "### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0Cz8gsuuVXv"
      },
      "source": [
        "def load_eurosat_dataset():\n",
        "\n",
        "  data_folders = sorted(glob.glob(\"2750/*\"))\n",
        "  # preprocessing steps for image\n",
        "  preprocess = transforms.Compose([transforms.ToTensor(),\n",
        "                                   transforms.RandomHorizontalFlip(),\n",
        "                                   transforms.RandomVerticalFlip(),\n",
        "                                   # normalization used on training resnet-50 data\n",
        "                                   transforms.Normalize(mean=[0.7137, 0.6628, 0.6519], \\\n",
        "                                                        std=[0.2970, 0.3017, 0.2979]),])\n",
        "  X = []\n",
        "  y = []\n",
        "  for idx, folder in enumerate(data_folders):\n",
        "    imgs = sorted(glob.glob(folder + \"/*.jpg\"))\n",
        "    for i in tqdm.tqdm(imgs):\n",
        "      img = Image.open(i)\n",
        "      img = preprocess(img)\n",
        "      X.append(img)\n",
        "      y.append(torch.tensor([idx]))\n",
        "  X = torch.stack(X, dim=0).float()\n",
        "  y = torch.stack(y, dim=0).flatten().long()\n",
        "  return X, y\n",
        "\n",
        "X, y = load_eurosat_dataset()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Ix_JsExm3G"
      },
      "source": [
        "### Initialize pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RuWR-tduVgo"
      },
      "source": [
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyfteOnBxswE"
      },
      "source": [
        "### Re-initialize final layer of pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCWvYSnbuZCf"
      },
      "source": [
        "model.fc = nn.Sequential(nn.Linear(2048, 10),\n",
        "                          nn.Softmax(dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca-5v8nTcwsd"
      },
      "source": [
        "### Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgetmdR0uZF3"
      },
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "def optim(pgroups, **kwargs):\n",
        "  return torch.optim.Adam(model.fc.parameters(), **kwargs)\n",
        "clf = NeuralNetClassifier(model, batch_size=512, max_epochs=10, lr=1e-3, optimizer=optim, device='cuda')\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPkhh7HuuZLh"
      },
      "source": [
        "clf = NeuralNetClassifier(model, batch_size=512, max_epochs=10, lr=1e-3, device='cuda')\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFsvhH_SxydR"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lC5DNiIufTd"
      },
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}