{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets can come from a wide range of sources and a wide range of formats. It will help us to think of all data fundamentally as arrays of numbers. For this reason, efficient storage and manipulation of numerical arrays is absolutely fundamental to the process of doing data science.\n",
    "\n",
    "`numpy` (short for Numerical Python) provides an efficient interface to store and operate on dense data buffers. In some ways, `numpy` arrays are like Python's built-in list type, but `numpy` arrays provide much more efficient storage and data operations as the arrays grow larger in size. `numpy` arrays form the core of nearly the entire ecosystem of data science tools in Python, so time spent learning to use `numpy` effectively will be valuable no matter what aspect of data science interests you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `numpy` library is imported by the statement `import numpy as np`. We then set a seed for the internal pseudorandom number generator `np.random.seed(123)` to make this notebook reproducible. \n",
    "\n",
    "We generate 3 arrays (`x1`, `x2`, and `x3`) and examine their dimension, shape, and size properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "x1 = np.random.randn(10,) # 1-D array\n",
    "x2 = np.random.randn(10, 10) # 2-D array\n",
    "x3 = np.random.randn(10, 10, 10) # 3-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x3 ndim: {} shape: {} size: {}\".format(x3.ndim, x3.shape, x3.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`matplotlib.pyplot` is a python library for plotting data. Here we create a function `plot` for plotting 2-dimensional arrays using the function `imshow`. More information on `imshow` can be found by calling `help(plt.imshow)` or reading the `matplotlib` documentation online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(array):\n",
    "    plt.imshow(array)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once created, `numpy` arrays can change dimensionality and shape while preserving array size. Here, we convert our 1-d `numpy` array into a column vector or a row vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x1.reshape(10, 1))\n",
    "plot(x1.reshape(10, 1))\n",
    "print(x1.reshape(1, 10))\n",
    "plot(x1.reshape(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `plt.subplots()` function, we can make more complex plots. Here, we use create a function `colorbar` for plotting `imshow` with a colorbar. This is also useful for creating multi-plots within the same image (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorbar(array):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(array)\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorbar(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.stack` function combines arrays by \"stacking\" them along a newly-created dimension `axis`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorbar(np.stack([x1, x1]))\n",
    "colorbar(np.stack([x1, x1], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.concatenate` function concatenates a list of arrays along an existing dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorbar(np.concatenate([x2, x2], axis=0))\n",
    "colorbar(np.concatenate([x2, x2], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` arrays can be indexed and slices similar to native Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x2[:, 0].shape, x2[:, 0:1].shape, x2[:4, :4].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` arrays can be split into a list of arrays using the `np.split` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(9).reshape((3, 3))\n",
    "print(x)\n",
    "xlist = np.split(x, x.shape[0], axis=0)\n",
    "print(len(xlist), xlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to random number generators, there are other useful functions for creating `numpy` arrays such as `np.zeros`, `np.ones`, and `np.arange`. Use these functions to create arrays and print the resulting arrays or try visualizing them with the plotting functions we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions on Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation on `numpy` arrays can be very fast, so long as one uses vectorized operations, generally implemented through `numpy`'s universal functions (ufuncs). Universal functions operate on `numpy` arrays element-wise. A comprehensive list of universal functions is available in the `numpy` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*np.pi, 16)\n",
    "sinx = np.sin(x)\n",
    "cosx = np.cos(x)\n",
    "for i in [x, sinx, cosx]: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, sinx)\n",
    "plt.plot(x, cosx)\n",
    "plt.legend(['sin(x)', 'cos(x)'])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are even more universal functions available in the `scipy.special` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf, erfc\n",
    "x = np.linspace(0, 2, 64)\n",
    "plt.plot(x, erf(x))\n",
    "plt.plot(x, erfc(x))\n",
    "plt.legend(['erf(x)', 'erfc(x)'])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` provides fast routines for performing various statistical operations on arrays. Let's try out `np.sum`, `np.min`, `np.max` `np.mean`, `np.std`, and `np.median`. Here, we generate some normally-distributed random numbers, visualize the array using a histogram (`plt.hist`), and then examine the statistics of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(1000,)\n",
    "plt.hist(x, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(x))\n",
    "print(np.min(x))\n",
    "print(np.max(x))\n",
    "print(np.mean(x))\n",
    "print(np.std(x))\n",
    "print(np.median(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These statistical on arrays are also available as dot-functions. Additionally, the `np.argmin` and `np.argmax` are useful functions for finding the indices of the minimum and maximum array values, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.sum())\n",
    "print(x.min())\n",
    "print(x.max())\n",
    "print(x.argmin())\n",
    "print(x.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Dot Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function using universal functions and aggregation operations to compute the dot product of two 1-d `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotprod(x, y):\n",
    "    z = None\n",
    "    return z\n",
    "\n",
    "x = np.random.randn(12,)\n",
    "y = np.random.randn(12,)\n",
    "z = dotprod(x, y)\n",
    "if z != None: print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting allows operations using arrays of different shape and dimensionality to be performed.\n",
    "\n",
    "Rules of broadcasting:\n",
    "1. If one of two arrays has a smaller dimension than the other, the shape of the smaller array is padded on the leading dimension (left) with ones until the number of dimensions match.\n",
    "2. If the shape of the two arrays does not match along one dimension, the array with shape 1 along that dimension is \"tiled\" to match the shape of the other array.\n",
    "3. If in any dimension the shapes do not agree and neither shape is 1, an error is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "y = np.arange(10).reshape(-1, 1)\n",
    "z = x*y\n",
    "print(x.shape, y.shape, z.shape)\n",
    "colorbar(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Standardizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common practice in data science when preparing input data for modeling is perform a linear transformation on an array such that the data has zero mean and unit standard deviation. This process is called \"standardization\". Let's standardize our data, first the hard way and then using broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((10, 5))\n",
    "print(x, x.shape)\n",
    "print(x.mean(axis=0), x.mean(axis=0).shape)\n",
    "print(x.std(axis=0), x.std(axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    x_mean = np.tile(x.mean(axis=0).reshape(1, -1), (10, 1))\n",
    "    x_std = np.tile(x.std(axis=0).reshape(1, -1), (10, 1))\n",
    "    print(x.shape, x_mean.shape, x_std.shape)\n",
    "    return (x - x_mean) / x_std\n",
    "\n",
    "def standardize_broadcasting(x):\n",
    "    return None\n",
    "\n",
    "x = np.random.random((10, 5))\n",
    "x = standardize(x)\n",
    "print(x.mean(axis=0), x.std(axis=0))\n",
    "\n",
    "x = standardize_broadcasting(x)\n",
    "if x != None:\n",
    "    print(x.mean(axis=0), x.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curve Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine how we can use data stored in numpy arrays to perform curve fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Function Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we attempt to fit a n-degree polynomial to the function $y(x) = sin(2x)$, where n is varied between 4-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*np.pi, 64)\n",
    "y = np.sin(2*x)\n",
    "\n",
    "for deg in [4, 6, 8, 10]:\n",
    "    z = np.polyfit(x, y, deg=deg)\n",
    "    y_fit = np.poly1d(z)\n",
    "    plt.plot(x, y_fit(x))\n",
    "    plt.plot(x, y)\n",
    "    plt.legend(['pred', 'target'])\n",
    "    plt.title(\"poly deg: {}\".format(deg))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always be aware that sometimes models fit with data can perform unexpected when applied outside the training data distribution. If the model you use to fit does not match well with the model generating the data (here, using a polynomial to fit a periodic function), you may see odd results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = np.linspace(0, 2.2*np.pi, 128)\n",
    "\n",
    "for deg in [4, 6, 8, 10]:\n",
    "    z = np.polyfit(x, y, deg=deg)\n",
    "    y_fit = np.poly1d(z)\n",
    "    plt.plot(x_pred, y_fit(x_pred))\n",
    "    plt.plot(x_pred, np.sin(2*x_pred))\n",
    "    plt.legend(['pred', 'target'])\n",
    "    plt.title(\"poly deg: {}\".format(deg))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Arbitrary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the `scipy.optimize.curve_fit` function to fit the same data to a periodic function. Be aware that that the starting guess for parameters has an effect on the outcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*np.pi, 64)\n",
    "y = np.sin(2.0*x)\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "def func(x, k):\n",
    "    return np.sin(k*x)\n",
    "\n",
    "pars, pcov = curve_fit(func, x, y, p0=[1.7])\n",
    "print(pars, pcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, func(x, *pars))\n",
    "plt.plot(x, y)\n",
    "plt.legend(['pred', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Estimating the Rate Constant of a First-Order Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a batch-reactor where we are performing a first-order, irreversible reaction with some species \"A\". In the problem, we'd like to determine the rate constant $k_1$ by measuring the concentration of species A, $C_A$, at fixed time intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a first order, irreversible reaction, we have from the law of mass action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\frac{dC_A}{dt} = k_1 C_A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting first order differential equation yields the solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ C_A(t) = C_{A,0} exp(-k_1t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $C_{A,0}$ is the starting concentration of species A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lieu of collection actual measurements, we will generate synthetic data using the solution to the ODE and add random noise to represent \"measurement error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.5 # s-1\n",
    "Ca_0 = 10.0 # mol\n",
    "noise = 5e-1 # measurement error\n",
    "t = np.linspace(0, 10, 20)\n",
    "Ca = Ca_0 * np.exp(-k*t)\n",
    "Ca += noise * np.random.randn(*Ca.shape)\n",
    "plt.scatter(t, Ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Rate Constant with Imperfect Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `curve_fit` to determine the rate constant $k_1$ given our \"measurement\" data and functional form of the concentration as a function of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
