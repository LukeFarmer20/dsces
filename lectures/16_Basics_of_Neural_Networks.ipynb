{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basics of Neural Networks.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4nOFqrdwzpD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6PD5BRQ2Bbu"
      },
      "source": [
        "# Basics of Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tTZWmZ42GIk"
      },
      "source": [
        "# Pytorch Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMeJorq32FGy"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KlSczvW8OBN"
      },
      "source": [
        "## Tensor Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vlfyj732KFY"
      },
      "source": [
        "# Pytorch functions similarly to NumPy and shares many common operations (sometimes with different syntax ..)\n",
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "z = x * y\n",
        "print(x, y, z)\n",
        "print(x.shape, y.shape, z.shape)\n",
        "\n",
        "x = x.reshape(1, -1)\n",
        "y = y.reshape(-1, 1)\n",
        "z = x @ y\n",
        "print(x, y, z)\n",
        "print(x.shape, y.shape, z.shape)\n",
        "print(z.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teiECFC2gr71"
      },
      "source": [
        "# Pytorch tensors can be converted to NumPy arrays and vice-versa\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "\n",
        "c = torch.tensor(b)\n",
        "print(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EcBDmIchogE"
      },
      "source": [
        "# Tensors can be moved between CPU and GPU using the .to method\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  x = torch.rand(12, 12).to(device)\n",
        "  evals, evecs = torch.eig(x, eigenvectors=True)\n",
        "  print(evals.cpu().numpy())\n",
        "  print(evecs.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypG_w75w8TUC"
      },
      "source": [
        "## Pytorch Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQUCc7L58YAC"
      },
      "source": [
        "# Most NN operations and computational graphs are represented as `torch.nn.Module` objects\n",
        "# For a summary of all NN building blocks, see https://pytorch.org/docs/stable/nn.html\n",
        "fc = nn.Linear(in_features=12, out_features=1)\n",
        "print(fc)\n",
        "\n",
        "X0 = torch.rand(5, 12)\n",
        "X1 = fc(X0)\n",
        "print(X1)\n",
        "print(X0.shape, X1.shape)\n",
        "\n",
        "print(fc.weight, fc.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4klKqJym8cFY"
      },
      "source": [
        "## Calculating Gradients via Backpropogation\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiAyiKtT8ct_"
      },
      "source": [
        "# Pytorch will construct a computational graph for backpropagation for variables that require gradients\n",
        "# and variables that depend on them\n",
        "x = torch.tensor([2.]).requires_grad_(True)\n",
        "y = x**2\n",
        "\n",
        "# The backward pass can be initiated by calling the backward function on a variable\n",
        "y.backward()\n",
        "print(x, y)\n",
        "\n",
        "# The gradient is stored as a .grad attribute after calling the backward function\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_mgQtaompFZ"
      },
      "source": [
        "# The gradients of vectors and matrices can be done with a few tricks\n",
        "x = torch.linspace(-4, 4, 50).cuda().requires_grad_(True)\n",
        "y = x**2\n",
        "print(x, y)\n",
        "# The backward pass can be initiated by calling the backward function on a variable\n",
        "y.backward(torch.ones(50,).cuda())\n",
        "print(x.grad)\n",
        "\n",
        "x_grad_n = x.grad.detach().cpu().numpy()\n",
        "x_n = x.detach().cpu().numpy()\n",
        "y_n = y.detach().cpu().numpy()\n",
        "\n",
        "plt.plot(x_n, y_n)\n",
        "plt.plot(x_n, x_grad_n)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y and grad_y')\n",
        "plt.legend(['y', 'grad_y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbRTMHEfkZZz"
      },
      "source": [
        "## Question: Calculate the gradient of sin(x) on the interval [0, 2pi]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ_w-nl3ksRH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd5fvd6y4gsc"
      },
      "source": [
        "# Building Neural Networks with `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER2De9cA4gCC"
      },
      "source": [
        "## The torch.nn.Sequential module can be used to construct sequential computation graphs\n",
        "model = torch.nn.Sequential(nn.Linear(12, 12),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(12, 1))\n",
        "X = torch.rand(5, 12)\n",
        "out = model(X)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKF_L1fi4bV8"
      },
      "source": [
        "# Example: Learning the XOR Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPx9C9OI57dS"
      },
      "source": [
        "## Construct dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iOU7aOL5HPb"
      },
      "source": [
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]]).float().to(device)\n",
        "y = torch.tensor([0, 1, 1, 0]).long().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFKzMIDx6O2m"
      },
      "source": [
        "## Construct model `torch.nn.Sequential`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sX_5iXM6X78"
      },
      "source": [
        "model = torch.nn.Sequential(nn.Linear(2, 10),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Linear(10, 2))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4paY_UEe6YUW"
      },
      "source": [
        "## Construct optimizer `torch.optim.SGD`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnVUTwaA7_LC"
      },
      "source": [
        "# The optimizer requires you pass a list of all adjustable parameters as well as the learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=1.0)\n",
        "ce_loss = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmMDwXyE8pYT"
      },
      "source": [
        "## Perform stochastic gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYXyLwrX80kt"
      },
      "source": [
        "for epoch in range(100):\n",
        "  model.zero_grad()\n",
        "  out = model(X)\n",
        "  loss = ce_loss(out, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if epoch%10 == 0: print(\"Epoch: {} Loss: {}\".format(epoch, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z2Ch8RA8ucv"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fySuzAu881W-"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "preds_scores = model(X)\n",
        "print(preds_scores)\n",
        "print(nn.functional.softmax(preds_scores, dim=1))\n",
        "preds = nn.functional.softmax(preds_scores, dim=1).max(dim=1)[1].detach().cpu().numpy()\n",
        "targets = y.cpu().numpy()\n",
        "print(accuracy_score(targets, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU7gdALm82VF"
      },
      "source": [
        "## Question: What is the smallest neural network that can learn the XOR function?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxIYyC_t9dkx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbEG8aOj5Lhe"
      },
      "source": [
        "# Example: Identifying Magnetic Materials with Chemical Formulas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQhTN3FB9KF4"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HugcTO7j5z2n"
      },
      "source": [
        "!pip install matminer\n",
        "!pip install skorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbAzGGpFwlZx"
      },
      "source": [
        "from matminer.datasets.convenience_loaders import load_mp\n",
        "from matminer.featurizers.conversions import StrToComposition\n",
        "from matminer.featurizers.composition import ElementProperty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWA_1eqdxcOw"
      },
      "source": [
        "df = load_mp()  # loads dataset in a pandas DataFrame object\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTs6bWP7p1UA"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxPYPDV89Mbb"
      },
      "source": [
        "## Featurize chemical formula dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnO7UzNr9OxJ"
      },
      "source": [
        "unwanted_columns = ['mpid', 'e_hull', 'gap pbe', 'elastic anisotropy',\n",
        "       'bulk modulus', 'shear modulus', 'e_form']\n",
        "df = df.drop(unwanted_columns, axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hKR0MAByqmn"
      },
      "source": [
        "# Convert formula to composition\n",
        "df = StrToComposition().featurize_dataframe(df, \"formula\", ignore_errors=True) \n",
        "\n",
        "# Create features based on composition\n",
        "ep_feat = ElementProperty.from_preset(preset_name=\"magpie\") \n",
        "\n",
        "# input the \"composition\" column to the featurizer\n",
        "df = ep_feat.featurize_dataframe(df, col_id=\"composition\", ignore_errors=True)  \n",
        "\n",
        "# drop rows with NaN values\n",
        "df = df.dropna(axis=0) \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaVWoYGJ1AA3"
      },
      "source": [
        "# Convert mu_b to magnetization classification problem\n",
        "y = df['mu_b'].values\n",
        "y = np.abs(y) > 1e-6\n",
        "\n",
        "# Drop non-numerical features and tasks from data frame\n",
        "excluded = ['mu_b', 'formula', 'composition']\n",
        "X = df.drop(excluded, axis=1).values\n",
        "\n",
        "# Standardize input data\n",
        "X = (X-X.mean(axis=-1, keepdims=True))/X.std(axis=-1, keepdims=True)\n",
        "\n",
        "# Convert numpy array to pytorch\n",
        "X = torch.tensor(X).float()\n",
        "y = torch.tensor(y).float()\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFvhH6N99PVW"
      },
      "source": [
        "## Construct model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC_PiQ--9TET"
      },
      "source": [
        "# Construct model (try changing dim!)\n",
        "num_features = X.shape[-1]\n",
        "dim = 1024\n",
        "\n",
        "model = nn.Sequential(nn.Linear(num_features, dim),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(dim, dim),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(dim, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIRQnWc-9Tsy"
      },
      "source": [
        "## Use `skorch` to handle optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkFYDh53zrmW"
      },
      "source": [
        "from skorch import NeuralNetBinaryClassifier\n",
        "net = NeuralNetBinaryClassifier(model, max_epochs=20, lr=1e-6, device='cuda')\n",
        "net.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}