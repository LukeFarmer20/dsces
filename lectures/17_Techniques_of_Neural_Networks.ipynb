{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Techniques of Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG9c7CJPHoIw"
      },
      "source": [
        "# Practical Tips for Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hZOf9Qfw36u"
      },
      "source": [
        "!pip install matminer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BmA_BBb70uV"
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2G7TWfK5bax"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from skorch import NeuralNetBinaryClassifier\n",
        "from matminer.datasets.convenience_loaders import load_mp\n",
        "from matminer.featurizers.conversions import StrToComposition\n",
        "from matminer.featurizers.composition import ElementProperty"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp2gN37_IBVH"
      },
      "source": [
        "## Load Material Property dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSgWX6dd5jf4"
      },
      "source": [
        "df = load_mp()  # loads dataset in a pandas DataFrame object\n",
        "df.head()\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4VxJY39IEjF"
      },
      "source": [
        "## Featurize dataset (~3 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQlLl2iC6KH3"
      },
      "source": [
        "# Convert formula to composition\n",
        "df = StrToComposition().featurize_dataframe(df, \"formula\", ignore_errors=True) \n",
        "\n",
        "# Create features based on composition\n",
        "ep_feat = ElementProperty.from_preset(preset_name=\"magpie\") \n",
        "\n",
        "# input the \"composition\" column to the featurizer\n",
        "df = ep_feat.featurize_dataframe(df, col_id=\"composition\", ignore_errors=True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sPIYtSSIRrp"
      },
      "source": [
        "## Construct dataset (heat of formation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "micQIdkN6Lhe"
      },
      "source": [
        "excluded = ['gap pbe', 'formula', 'composition', 'mpid', 'e_hull', 'elastic anisotropy',\n",
        "       'bulk modulus', 'shear modulus', 'mu_b']\n",
        "df_ = df.drop(excluded, axis=1).sample(frac=1).reset_index(drop=True)\n",
        "df_ = df_.dropna(axis=0) \n",
        "\n",
        "# Convert gap to metallic classification problem\n",
        "y = df_['e_form'].values.reshape(-1, 1)\n",
        "\n",
        "# Drop tasks from data frame\n",
        "excluded = ['e_form']\n",
        "df_ = df_.drop(excluded, axis=1)\n",
        "X = df_.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukFe5JY6IYHx"
      },
      "source": [
        "## Split and Standardize dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2iQPZ17ILq1"
      },
      "source": [
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9)\n",
        "\n",
        "# Standardize input data\n",
        "X_mean = X_train.mean(axis=0, keepdims=True)\n",
        "X_std = X_train.std(axis=0, keepdims=True)\n",
        "y_mean = y_train.mean(keepdims=True)\n",
        "y_std = y_train.std(keepdims=True)\n",
        "\n",
        "X_train = (X_train-X_mean)/X_std\n",
        "X_test = (X_test-X_mean)/X_std\n",
        "y_train = (y_train-y_mean)/y_std\n",
        "y_test = (y_test-y_mean)/y_std\n",
        "\n",
        "# Convert numpy array to pytorch\n",
        "X_train = torch.tensor(X_train).float()\n",
        "X_test = torch.tensor(X_test).float()\n",
        "y_train = torch.tensor(y_train).float()\n",
        "y_test = torch.tensor(y_test).float()\n",
        "print(X_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tYMQ8d5I-hb"
      },
      "source": [
        "## Construct model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT9OmPjj6Nid"
      },
      "source": [
        "num_features = X_train.shape[-1]\n",
        "dim = 1024\n",
        "\n",
        "model = nn.Sequential(nn.Linear(num_features, dim),\n",
        "                      nn.ReLU(),\n",
        "                      *[nn.Linear(dim, dim),\n",
        "                      nn.BatchNorm1d(dim),\n",
        "                      nn.ReLU()]*2,\n",
        "                      nn.Linear(dim, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PznzTqEoJCS2"
      },
      "source": [
        "## Optimize model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs28txw26YcP"
      },
      "source": [
        "from skorch import NeuralNetRegressor\n",
        "net = NeuralNetRegressor(model, batch_size=64, max_epochs=20, lr=2e-4, device='cuda')\n",
        "net.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOhr70QAJE-c"
      },
      "source": [
        "## Evaluate performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH9Oi1Dk7hDQ"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "preds = net.predict(X_train)\n",
        "preds = preds*y_std + y_mean\n",
        "targets = y_train.numpy()*y_std + y_mean\n",
        "print(mean_absolute_error(targets, preds))\n",
        "print(r2_score(targets, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRRn_EvOGxlC"
      },
      "source": [
        "preds = net.predict(X_test)\n",
        "preds = preds*y_std + y_mean\n",
        "targets = y_test.numpy()*y_std + y_mean\n",
        "print(mean_absolute_error(targets, preds))\n",
        "print(r2_score(targets, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeGcdbk9LKpH"
      },
      "source": [
        "## Optimizers: Learning Rate Scheduler and Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCDWtGpGLJ3P"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(num_features, dim),\n",
        "                      nn.ReLU(),\n",
        "                      *[nn.Linear(dim, dim),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(p=0.2)]*5,\n",
        "                      nn.Linear(dim, 1))\n",
        "\n",
        "from skorch.callbacks import LRScheduler\n",
        "callbacks=[\n",
        "        ('lr_scheduler',\n",
        "         LRScheduler(policy='ReduceLROnPlateau',\n",
        "                     min_lr=1e-5)),\n",
        "    ]\n",
        "net = NeuralNetRegressor(model, batch_size=64, max_epochs=20, lr=2e-3, device='cuda', callbacks=callbacks)\n",
        "net.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMDITF8zLzIT"
      },
      "source": [
        "preds = net.predict(X_train)\n",
        "preds = preds*y_std + y_mean\n",
        "targets = y_train.numpy()*y_std + y_mean\n",
        "print(mean_absolute_error(targets, preds))\n",
        "print(r2_score(targets, preds))\n",
        "preds = net.predict(X_test)\n",
        "preds = preds*y_std + y_mean\n",
        "targets = y_test.numpy()*y_std + y_mean\n",
        "print(mean_absolute_error(targets, preds))\n",
        "print(r2_score(targets, preds))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}