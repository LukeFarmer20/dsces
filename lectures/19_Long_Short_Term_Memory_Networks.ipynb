{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Long-Short_Term_Memory_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h5I1X-bATCy"
      },
      "source": [
        "!pip install skorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nztLOtXTAJTo"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import skorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syx7UmkLAVMk"
      },
      "source": [
        "os.system('wget https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFmMvpaqESTN"
      },
      "source": [
        "# Time-Series Forecasting with Long-Short Term Memory Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr3S0KKBEg8b"
      },
      "source": [
        "##  Beijing PM2.5 Data Set \n",
        "\n",
        "Reference: Liang, X., Zou, T., Guo, B., Li, S., Zhang, H., Zhang, S., Huang, H. and Chen, S. X. (2015). [Assessing Beijing's PM2.5 pollution: severity, weather impact, APEC and winter heating](https://royalsocietypublishing.org/doi/10.1098/rspa.2015.0257). Proceedings of the Royal Society A, 471, 20150257.\n",
        "\n",
        "This hourly data set contains the PM2.5 data of US Embassy in Beijing. Meanwhile, meteorological data from Beijing Capital International Airport are also included.\n",
        "\n",
        "Dataset Description:\n",
        "```\n",
        "No: row number\n",
        "year: year of data in this row\n",
        "month: month of data in this row\n",
        "day: day of data in this row\n",
        "hour: hour of data in this row\n",
        "pm2.5: PM2.5 concentration (ug/m^3)\n",
        "DEWP: Dew Point (â„ƒ)\n",
        "TEMP: Temperature (â„ƒ)\n",
        "PRES: Pressure (hPa)\n",
        "cbwd: Combined wind direction\n",
        "Iws: Cumulated wind speed (m/s)\n",
        "Is: Cumulated hours of snow\n",
        "Ir: Cumulated hours of rain\n",
        "``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn-rKm5fAZCd"
      },
      "source": [
        "df = pd.read_csv('PRSA_data_2010.1.1-2014.12.31.csv')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gq12y76JFJXj"
      },
      "source": [
        "## Visualize time series data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Ae4pt6C2DX"
      },
      "source": [
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 15\n",
        "fig_size[1] = 5\n",
        "plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "plt.title('pm2.5 vs Time')\n",
        "plt.ylabel('pm2.5')\n",
        "plt.xlabel('Time')\n",
        "plt.grid(True)\n",
        "plt.autoscale(axis='x',tight=True)\n",
        "plt.plot(df['pm2.5'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WphJGhdGDWm"
      },
      "source": [
        "## Process dataset features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNLVNPlHGDJH"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "cbwd = df['cbwd'].values.reshape(-1, 1)\n",
        "ohe = OneHotEncoder()\n",
        "cbwd_ohe = ohe.fit_transform(cbwd).toarray()\n",
        "print(cbwd_ohe.shape)\n",
        "print(ohe.categories_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfISKsOZEKBW"
      },
      "source": [
        "pm = df['pm2.5'].values\n",
        "\n",
        "to_drop = ['No', 'pm2.5', 'cbwd']\n",
        "X_df = df.drop(labels=to_drop, axis=1)\n",
        "X = X_df.values\n",
        "X = np.concatenate([X, cbwd_ohe], axis=1)\n",
        "print(X.shape, pm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LJJSJ0wGHnT"
      },
      "source": [
        "## Create input/output sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjYIKI4VGPiO"
      },
      "source": [
        "import tqdm\n",
        "def create_sequences(data, window):\n",
        "    L = len(data)\n",
        "    inputs = np.zeros((L-window, window))\n",
        "    labels = np.zeros((L-window, 1))\n",
        "    for i in tqdm.tqdm(range(L-window)):\n",
        "        inputs[i] = data[i:i+window]\n",
        "        labels[i] = data[i+window:i+window+1]   \n",
        "    return inputs, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWSp4x25KUsB"
      },
      "source": [
        "window = 5\n",
        "pm_feat, y = create_sequences(pm, window=window)\n",
        "print(pm_feat.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1L47j6ZNogL"
      },
      "source": [
        "X = X[window:]\n",
        "X = np.concatenate([X, pm_feat], axis=1)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alfXt7rvIvt5"
      },
      "source": [
        "X = X[~np.isnan(y.flatten())]\n",
        "y = y[~np.isnan(y)]\n",
        "\n",
        "for i in range(X.shape[1]):\n",
        "  y = y[~np.isnan(X[:, i])]\n",
        "  X = X[~np.isnan(X[:, i])]\n",
        "\n",
        "y = y.reshape((-1, 1))\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeQ9sJdoOk-l"
      },
      "source": [
        "n_data_pts = X.shape[0]\n",
        "train_idx = int(0.9 * n_data_pts)\n",
        "X_train = X[:train_idx]\n",
        "X_test = X[train_idx:]\n",
        "y_train = y[:train_idx]\n",
        "y_test = y[train_idx:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lhs9-WnPugQ"
      },
      "source": [
        "X_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_train = X_scaler.fit_transform(X_train)\n",
        "X_test = X_scaler.transform(X_test)\n",
        "y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "y_train = y_scaler.fit_transform(y_train)\n",
        "y_test = y_scaler.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcHfXylDQJDH"
      },
      "source": [
        "X_train = torch.tensor(X_train).float()\n",
        "X_test = torch.tensor(X_test).float()\n",
        "y_train = torch.tensor(y_train).float()\n",
        "y_test = torch.tensor(y_test).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH1D3ABJGQKo"
      },
      "source": [
        "## Create LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylafg7DzGTak"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):\n",
        "        super().__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
        "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
        "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
        "                            torch.zeros(1,1,self.hidden_layer_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, self.hidden_cell = self.lstm(x.view(len(x), 1, -1), self.hidden_cell)\n",
        "        out = self.linear(lstm_out.view(len(x), -1))\n",
        "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
        "                            torch.zeros(1,1,self.hidden_layer_size))\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEyeorGQGT51"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpSwodNVGV4O"
      },
      "source": [
        "from skorch import NeuralNetRegressor\n",
        "model = Net(input_size=X.shape[-1], hidden_layer_size=100, output_size=y.shape[-1])\n",
        "regr = NeuralNetRegressor(model, batch_size=64, max_epochs=15, lr=1e-4)\n",
        "regr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1Duw43sGWjk"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAz6WtYAGYOl"
      },
      "source": [
        "print(\"Train R2 score: {} Test R2 score: {}\".format(regr.score(X_train, y_train), regr.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3szsiw_7QnkY"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "train_preds = y_scaler.inverse_transform(regr.predict(X_train))\n",
        "test_preds = y_scaler.inverse_transform(regr.predict(X_test))\n",
        "train_targets = y_scaler.inverse_transform(y_train)\n",
        "test_targets = y_scaler.inverse_transform(y_test)\n",
        "\n",
        "train_r2 = r2_score(train_targets, train_preds)\n",
        "test_r2 = r2_score(test_targets, test_preds)\n",
        "train_mae = mean_absolute_error(train_targets, train_preds)\n",
        "test_mae = mean_absolute_error(test_targets, test_preds)\n",
        "print(train_r2, test_r2, train_mae, test_mae)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}